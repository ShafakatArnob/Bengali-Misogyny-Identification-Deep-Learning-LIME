{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\user\\anaconda3\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\user\\anaconda3\\lib\\site-packages (0.15.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->torchvision) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.11)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in c:\\users\\user\\anaconda3\\lib\\site-packages (4.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.3.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2022.7.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.9.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting accelerate==0.20.3\n",
      "  Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
      "     -------------------------------------- 227.6/227.6 kB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\anaconda3\\lib\\site-packages (from accelerate==0.20.3) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\user\\anaconda3\\lib\\site-packages (from accelerate==0.20.3) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from accelerate==0.20.3) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from accelerate==0.20.3) (1.24.3)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from accelerate==0.20.3) (2.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from packaging>=20.0->accelerate==0.20.3) (3.0.9)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.6.0->accelerate==0.20.3) (2.11.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.6.0->accelerate==0.20.3) (1.10.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.6.0->accelerate==0.20.3) (4.3.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.6.0->accelerate==0.20.3) (2.8.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.6.0->accelerate==0.20.3) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.6.0->accelerate==0.20.3) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sympy->torch>=1.6.0->accelerate==0.20.3) (1.2.1)\n",
      "Installing collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.19.0\n",
      "    Uninstalling accelerate-0.19.0:\n",
      "      Successfully uninstalled accelerate-0.19.0\n",
      "Successfully installed accelerate-0.20.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision\n",
    "%pip install transformers \n",
    "%pip install accelerate==0.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os\n",
    "import pandas as pd\n",
    "from transformers import pipeline, BertForSequenceClassification, BertTokenizerFast\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sub-task A</th>\n",
       "      <th>Sub-task B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3883</th>\n",
       "      <td>C59.1200</td>\n",
       "      <td>great show</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>C7.2451.3</td>\n",
       "      <td>There just problem with the movie and where I ...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>C33.644.4</td>\n",
       "      <td>Rohit barman nice</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329</th>\n",
       "      <td>C4.1321</td>\n",
       "      <td>Totally agreed with your practicality but ther...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>C10.576</td>\n",
       "      <td>From today onward she will be called kungfu bitc?</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                               Text Sub-task A  \\\n",
       "3883   C59.1200                                         great show        NAG   \n",
       "2439  C7.2451.3  There just problem with the movie and where I ...        NAG   \n",
       "1786  C33.644.4                                  Rohit barman nice        NAG   \n",
       "2329    C4.1321  Totally agreed with your practicality but ther...        NAG   \n",
       "2567    C10.576  From today onward she will be called kungfu bitc?        NAG   \n",
       "\n",
       "     Sub-task B  \n",
       "3883       NGEN  \n",
       "2439       NGEN  \n",
       "1786       NGEN  \n",
       "2329       NGEN  \n",
       "2567       NGEN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT_DIR = './trac2-dataset/eng/'\n",
    "\n",
    "df_org= pd.read_csv(ROOT_DIR + \"trac2_eng_train.csv\")\n",
    "\n",
    "df_org = df_org.sample(frac=1.0, random_state=42)\n",
    "\n",
    "df_org.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NGEN', 'GEN']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df_org['Sub-task B'].unique().tolist()\n",
    "labels = [s.strip() for s in labels ]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGEN\n",
      "GEN\n"
     ]
    }
   ],
   "source": [
    "for key, value in enumerate(labels):\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LABELS= len(labels)\n",
    "\n",
    "id2label={id:label for id,label in enumerate(labels)}\n",
    "\n",
    "label2id={label:id for id,label in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NGEN': 0, 'GEN': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'NGEN', 1: 'GEN'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sub-task A</th>\n",
       "      <th>Sub-task B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3883</th>\n",
       "      <td>C59.1200</td>\n",
       "      <td>great show</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>C7.2451.3</td>\n",
       "      <td>There just problem with the movie and where I ...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>C33.644.4</td>\n",
       "      <td>Rohit barman nice</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329</th>\n",
       "      <td>C4.1321</td>\n",
       "      <td>Totally agreed with your practicality but ther...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>C10.576</td>\n",
       "      <td>From today onward she will be called kungfu bitc?</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                               Text Sub-task A  \\\n",
       "3883   C59.1200                                         great show        NAG   \n",
       "2439  C7.2451.3  There just problem with the movie and where I ...        NAG   \n",
       "1786  C33.644.4                                  Rohit barman nice        NAG   \n",
       "2329    C4.1321  Totally agreed with your practicality but ther...        NAG   \n",
       "2567    C10.576  From today onward she will be called kungfu bitc?        NAG   \n",
       "\n",
       "     Sub-task B  \n",
       "3883       NGEN  \n",
       "2439       NGEN  \n",
       "1786       NGEN  \n",
       "2329       NGEN  \n",
       "2567       NGEN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_org.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_org[\"labels\"]=df_org['Sub-task B'].map(lambda x: label2id[x.strip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sub-task A</th>\n",
       "      <th>Sub-task B</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3883</th>\n",
       "      <td>C59.1200</td>\n",
       "      <td>great show</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>C7.2451.3</td>\n",
       "      <td>There just problem with the movie and where I ...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>C33.644.4</td>\n",
       "      <td>Rohit barman nice</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329</th>\n",
       "      <td>C4.1321</td>\n",
       "      <td>Totally agreed with your practicality but ther...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>C10.576</td>\n",
       "      <td>From today onward she will be called kungfu bitc?</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                               Text Sub-task A  \\\n",
       "3883   C59.1200                                         great show        NAG   \n",
       "2439  C7.2451.3  There just problem with the movie and where I ...        NAG   \n",
       "1786  C33.644.4                                  Rohit barman nice        NAG   \n",
       "2329    C4.1321  Totally agreed with your practicality but ther...        NAG   \n",
       "2567    C10.576  From today onward she will be called kungfu bitc?        NAG   \n",
       "\n",
       "     Sub-task B  labels  \n",
       "3883       NGEN       0  \n",
       "2439       NGEN       0  \n",
       "1786       NGEN       0  \n",
       "2329       NGEN       0  \n",
       "2567       NGEN       0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_org.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Sub-task B'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_org['Sub-task B'].value_counts().plot(kind='pie', figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f134558ae34a4d34ac26a7da9de2aa5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading ()/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\", max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=NUM_LABELS, id2label=id2label, label2id=label2id)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting df_org\n",
    "\n",
    "SIZE= df_org.shape[0]\n",
    "\n",
    "train_texts= list(df_org.Text[:SIZE//2])\n",
    "\n",
    "val_texts=   list(df_org.Text[SIZE//2:(3*SIZE)//4 ])\n",
    "\n",
    "test_texts=  list(df_org.Text[(3*SIZE)//4:])\n",
    "\n",
    "train_labels= list(df_org.labels[:SIZE//2])\n",
    "\n",
    "val_labels=   list(df_org.labels[SIZE//2:(3*SIZE)//4])\n",
    "\n",
    "test_labels=  list(df_org.labels[(3*SIZE)//4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2131"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2131, 1066, 1066)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_texts), len(val_texts), len(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings  = tokenizer(val_texts, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset class for handling tokenized text data and corresponding labels.\n",
    "    Inherits from torch.utils.data.Dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, encodings, labels):\n",
    "        \"\"\"\n",
    "        Initializes the DataLoader class with encodings and labels.\n",
    "\n",
    "        Args:\n",
    "            encodings (dict): A dictionary containing tokenized input text data\n",
    "                              (e.g., 'input_ids', 'token_type_ids', 'attention_mask').\n",
    "            labels (list): A list of integer labels for the input text data.\n",
    "        \"\"\"\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a dictionary containing tokenized data and the corresponding label for a given index.\n",
    "\n",
    "        Args:\n",
    "            idx (int): The index of the data item to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            item (dict): A dictionary containing the tokenized data and the corresponding label.\n",
    "        \"\"\"\n",
    "        # Retrieve tokenized data for the given index\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        # Add the label for the given index to the item dictionary\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of data items in the dataset.\n",
    "\n",
    "        Returns:\n",
    "            (int): The number of data items in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_encodings, train_labels)\n",
    "\n",
    "val_dataloader = DataLoader(val_encodings, val_labels)\n",
    "\n",
    "test_dataset = DataLoader(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with Trainer Class\n",
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    \"\"\"\n",
    "    Computes accuracy, F1, precision, and recall for a given set of predictions.\n",
    "\n",
    "    Args:\n",
    "        pred (obj): An object containing label_ids and predictions attributes.\n",
    "            - label_ids (array-like): A 1D array of true class labels.\n",
    "            - predictions (array-like): A 2D array where each row represents\n",
    "              an observation, and each column represents the probability of\n",
    "              that observation belonging to a certain class.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the following metrics:\n",
    "            - Accuracy (float): The proportion of correctly classified instances.\n",
    "            - F1 (float): The macro F1 score, which is the harmonic mean of precision\n",
    "              and recall. Macro averaging calculates the metric independently for\n",
    "              each class and then takes the average.\n",
    "            - Precision (float): The macro precision, which is the number of true\n",
    "              positives divided by the sum of true positives and false positives.\n",
    "            - Recall (float): The macro recall, which is the number of true positives\n",
    "              divided by the sum of true positives and false negatives.\n",
    "    \"\"\"\n",
    "    # Extract true labels from the input object\n",
    "    labels = pred.label_ids\n",
    "\n",
    "    # Obtain predicted class labels by finding the column index with the maximum probability\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    # Compute macro precision, recall, and F1 score using sklearn's precision_recall_fscore_support function\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "\n",
    "    # Calculate the accuracy score using sklearn's accuracy_score function\n",
    "    acc = accuracy_score(labels, preds)\n",
    "\n",
    "    # Return the computed metrics as a dictionary\n",
    "    return {\n",
    "        'Accuracy': acc,\n",
    "        'F1': f1,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    # The output directory where the model predictions and checkpoints will be written\n",
    "    output_dir='./eng-monolingual-bert-results',\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    #  The number of epochs, defaults to 3.0\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    # Number of steps used for a linear warmup\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_strategy='steps',\n",
    "   # TensorBoard log directory\n",
    "    logging_dir='./eng-monolingual-bert-logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=10,\n",
    "    save_strategy=\"steps\",\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    # the pre-trained model that will be fine-tuned\n",
    "    model=model,\n",
    "     # training arguments that we defined above\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataloader,\n",
    "    eval_dataset=val_dataloader,\n",
    "    compute_metrics= compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='534' max='534' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [534/534 26:05:28, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.482100</td>\n",
       "      <td>0.478505</td>\n",
       "      <td>0.919325</td>\n",
       "      <td>0.478983</td>\n",
       "      <td>0.460094</td>\n",
       "      <td>0.499490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.485600</td>\n",
       "      <td>0.453392</td>\n",
       "      <td>0.919325</td>\n",
       "      <td>0.478983</td>\n",
       "      <td>0.460094</td>\n",
       "      <td>0.499490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.463300</td>\n",
       "      <td>0.422154</td>\n",
       "      <td>0.919325</td>\n",
       "      <td>0.478983</td>\n",
       "      <td>0.460094</td>\n",
       "      <td>0.499490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.360300</td>\n",
       "      <td>0.380065</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.479238</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.325600</td>\n",
       "      <td>0.322510</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.479238</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.358100</td>\n",
       "      <td>0.284826</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.479238</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>0.269339</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.479238</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.118700</td>\n",
       "      <td>0.277602</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.479238</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.309400</td>\n",
       "      <td>0.294902</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.479238</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.251600</td>\n",
       "      <td>0.304708</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.479238</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.346600</td>\n",
       "      <td>0.315069</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.479238</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.361800</td>\n",
       "      <td>0.281724</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.479238</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.162700</td>\n",
       "      <td>0.290446</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.479238</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.398200</td>\n",
       "      <td>0.300614</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.479238</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.311900</td>\n",
       "      <td>0.288266</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.479238</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.287100</td>\n",
       "      <td>0.271628</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.479238</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.234200</td>\n",
       "      <td>0.268626</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.479238</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.225300</td>\n",
       "      <td>0.308200</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.479238</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.299400</td>\n",
       "      <td>0.305626</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.479238</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.372000</td>\n",
       "      <td>0.291928</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.479238</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.153300</td>\n",
       "      <td>0.344052</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.479238</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.312300</td>\n",
       "      <td>0.243830</td>\n",
       "      <td>0.919325</td>\n",
       "      <td>0.478983</td>\n",
       "      <td>0.460094</td>\n",
       "      <td>0.499490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.091200</td>\n",
       "      <td>0.287393</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.479238</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.246300</td>\n",
       "      <td>0.354130</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.479238</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.253000</td>\n",
       "      <td>0.352221</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.479238</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.199300</td>\n",
       "      <td>0.329962</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.479238</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.431000</td>\n",
       "      <td>0.280727</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.479238</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.287610</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.479238</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.254700</td>\n",
       "      <td>0.325383</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.479238</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.355700</td>\n",
       "      <td>0.232919</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.479238</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.237400</td>\n",
       "      <td>0.262067</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.479238</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>0.354752</td>\n",
       "      <td>0.921201</td>\n",
       "      <td>0.491100</td>\n",
       "      <td>0.960563</td>\n",
       "      <td>0.505882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.239700</td>\n",
       "      <td>0.247762</td>\n",
       "      <td>0.929644</td>\n",
       "      <td>0.643607</td>\n",
       "      <td>0.813942</td>\n",
       "      <td>0.601805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>0.331908</td>\n",
       "      <td>0.932458</td>\n",
       "      <td>0.622283</td>\n",
       "      <td>0.932889</td>\n",
       "      <td>0.581843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.467700</td>\n",
       "      <td>0.324135</td>\n",
       "      <td>0.928705</td>\n",
       "      <td>0.577099</td>\n",
       "      <td>0.964049</td>\n",
       "      <td>0.552941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.304500</td>\n",
       "      <td>0.346159</td>\n",
       "      <td>0.925891</td>\n",
       "      <td>0.546581</td>\n",
       "      <td>0.962736</td>\n",
       "      <td>0.535294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.375800</td>\n",
       "      <td>0.264730</td>\n",
       "      <td>0.929644</td>\n",
       "      <td>0.594975</td>\n",
       "      <td>0.923229</td>\n",
       "      <td>0.564196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.321900</td>\n",
       "      <td>0.300559</td>\n",
       "      <td>0.916510</td>\n",
       "      <td>0.632822</td>\n",
       "      <td>0.695472</td>\n",
       "      <td>0.605415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.213400</td>\n",
       "      <td>0.277226</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.672920</td>\n",
       "      <td>0.721344</td>\n",
       "      <td>0.645062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.232000</td>\n",
       "      <td>0.297577</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.626214</td>\n",
       "      <td>0.741343</td>\n",
       "      <td>0.592864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.358100</td>\n",
       "      <td>0.259256</td>\n",
       "      <td>0.918386</td>\n",
       "      <td>0.630326</td>\n",
       "      <td>0.705336</td>\n",
       "      <td>0.601061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.101700</td>\n",
       "      <td>0.294789</td>\n",
       "      <td>0.924953</td>\n",
       "      <td>0.635331</td>\n",
       "      <td>0.757955</td>\n",
       "      <td>0.599256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.051600</td>\n",
       "      <td>0.387931</td>\n",
       "      <td>0.924015</td>\n",
       "      <td>0.627747</td>\n",
       "      <td>0.750515</td>\n",
       "      <td>0.593374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.491700</td>\n",
       "      <td>0.404696</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.479238</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.110800</td>\n",
       "      <td>0.327153</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.479238</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.183200</td>\n",
       "      <td>0.280999</td>\n",
       "      <td>0.932458</td>\n",
       "      <td>0.622283</td>\n",
       "      <td>0.932889</td>\n",
       "      <td>0.581843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.194200</td>\n",
       "      <td>0.228290</td>\n",
       "      <td>0.930582</td>\n",
       "      <td>0.611791</td>\n",
       "      <td>0.899080</td>\n",
       "      <td>0.575451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.235300</td>\n",
       "      <td>0.186250</td>\n",
       "      <td>0.938086</td>\n",
       "      <td>0.717437</td>\n",
       "      <td>0.844531</td>\n",
       "      <td>0.665491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.153900</td>\n",
       "      <td>0.200684</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.727885</td>\n",
       "      <td>0.842680</td>\n",
       "      <td>0.676746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.284600</td>\n",
       "      <td>0.206920</td>\n",
       "      <td>0.938086</td>\n",
       "      <td>0.733500</td>\n",
       "      <td>0.825549</td>\n",
       "      <td>0.686982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.097800</td>\n",
       "      <td>0.333377</td>\n",
       "      <td>0.929644</td>\n",
       "      <td>0.586854</td>\n",
       "      <td>0.964489</td>\n",
       "      <td>0.558824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.365700</td>\n",
       "      <td>0.261064</td>\n",
       "      <td>0.930582</td>\n",
       "      <td>0.596410</td>\n",
       "      <td>0.964929</td>\n",
       "      <td>0.564706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.297100</td>\n",
       "      <td>0.250240</td>\n",
       "      <td>0.928705</td>\n",
       "      <td>0.593562</td>\n",
       "      <td>0.887939</td>\n",
       "      <td>0.563687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=534, training_loss=0.26947656296165695, metrics={'train_runtime': 93952.347, 'train_samples_per_second': 0.045, 'train_steps_per_second': 0.006, 'total_flos': 1121379317944320.0, 'train_loss': 0.26947656296165695, 'epoch': 2.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_Accuracy</th>\n",
       "      <th>eval_F1</th>\n",
       "      <th>eval_Precision</th>\n",
       "      <th>eval_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.122281</td>\n",
       "      <td>0.963867</td>\n",
       "      <td>0.838223</td>\n",
       "      <td>0.896887</td>\n",
       "      <td>0.796584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>0.206920</td>\n",
       "      <td>0.938086</td>\n",
       "      <td>0.733500</td>\n",
       "      <td>0.825549</td>\n",
       "      <td>0.686982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.206812</td>\n",
       "      <td>0.935272</td>\n",
       "      <td>0.697720</td>\n",
       "      <td>0.776910</td>\n",
       "      <td>0.658063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eval_loss  eval_Accuracy   eval_F1  eval_Precision  eval_Recall\n",
       "train   0.122281       0.963867  0.838223        0.896887     0.796584\n",
       "val     0.206920       0.938086  0.733500        0.825549     0.686982\n",
       "test    0.206812       0.935272  0.697720        0.776910     0.658063"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q=[trainer.evaluate(eval_dataset=df_org) for df_org in [train_dataloader, val_dataloader, test_dataset]]\n",
    "\n",
    "pd.DataFrame(q, index=[\"train\",\"val\",\"test\"]).iloc[:,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    \"\"\"\n",
    "    Predicts the class label for a given input text\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text for which the class label needs to be predicted.\n",
    "\n",
    "    Returns:\n",
    "        probs (torch.Tensor): Class probabilities for the input text.\n",
    "        pred_label_idx (torch.Tensor): The index of the predicted class label.\n",
    "        pred_label (str): The predicted class label.\n",
    "    \"\"\"\n",
    "    # Tokenize the input text and move tensors to the GPU if available\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").to(\"cpu\")\n",
    "\n",
    "    # Get model output (logits)\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    probs = outputs[0].softmax(1)\n",
    "    \"\"\" Explanation outputs: The BERT model returns a tuple containing the output logits (and possibly other elements depending on the model configuration). In this case, the output logits are the first element in the tuple, which is why we access it using outputs[0].\n",
    "\n",
    "    outputs[0]: This is a tensor containing the raw output logits for each class. The shape of the tensor is (batch_size, num_classes) where batch_size is the number of input samples (in this case, 1, as we are predicting for a single input text) and num_classes is the number of target classes.\n",
    "\n",
    "    softmax(1): The softmax function is applied along dimension 1 (the class dimension) to convert the raw logits into class probabilities. Softmax normalizes the logits so that they sum to 1, making them interpretable as probabilities. \"\"\"\n",
    "\n",
    "    # Get the index of the class with the highest probability\n",
    "    # argmax() finds the index of the maximum value in the tensor along a specified dimension.\n",
    "    # By default, if no dimension is specified, it returns the index of the maximum value in the flattened tensor.\n",
    "    pred_label_idx = probs.argmax()\n",
    "\n",
    "    # Now map the predicted class index to the actual class label \n",
    "    # Since pred_label_idx is a tensor containing a single value (the predicted class index), \n",
    "    # the .item() method is used to extract the value as a scalar\n",
    "    pred_label = model.config.id2label[pred_label_idx.item()]\n",
    "\n",
    "    return probs, pred_label_idx, pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3696, 0.6304]], grad_fn=<SoftmaxBackward0>), tensor(1), 'GEN')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with a an example text in Turkish\n",
    "text = \"Girls are prostitute\"\n",
    "# \"Machine Learning itself is moving towards more and more automated\"\n",
    "predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('eng-monolingual-bart-trained\\\\tokenizer_config.json',\n",
       " 'eng-monolingual-bart-trained\\\\special_tokens_map.json',\n",
       " 'eng-monolingual-bart-trained\\\\vocab.txt',\n",
       " 'eng-monolingual-bart-trained\\\\added_tokens.json',\n",
       " 'eng-monolingual-bart-trained\\\\tokenizer.json')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"eng-monolingual-bart-trained\"\n",
    "trainer.save_model(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"eng-monolingual-bart-trained\"\n",
    "\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer= BertTokenizerFast.from_pretrained(model_path)\n",
    "nlp= pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'GEN', 'score': 0.6303809285163879}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"Girls are prostitute\")\n",
    "# Today the weather is very nice, I want to go for a walk outside\n",
    "\n",
    "# Gives below output\n",
    "#[{'label': 'saglik', 'score': 0.8295329213142395}]\n",
    "# \"Saglik\" is a Turkish word that means \"health\" in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NGEN', 'score': 0.7858740091323853}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"Girls are sluts\")\n",
    "# Deep Learning and AI is going to change the world\n",
    "\n",
    "# gives below output\n",
    "#[{'label': 'teknoloji', 'score': 0.9932782053947449}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NGEN', 'score': 0.9934313893318176}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"Women should be in the kitchen\")\n",
    "# Due to recent volatility in the economy, the stock market index has been at quite low levels\n",
    "\n",
    "#gives below output\n",
    "#[{'label': 'ekonomi', 'score': 0.9850727915763855}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
